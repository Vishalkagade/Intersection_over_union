{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d793fe78",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46ecda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9d0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be829e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8386, 0.6306, 0.9933], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6219a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y*y*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44cde76e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "print(x.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59fb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we want to update out weight then their is no need of grad func_\n",
    "#there are three ways\n",
    "#x.reuires_grad(false)\n",
    "#x.detach()\n",
    "#witrh torch.no_grad():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d172f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3810, -1.4852,  0.1444], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.3810, -1.4852,  0.1444])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x = torch.randn(3,requires_grad = True)\n",
    "print(x)\n",
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae775286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5425, 1.9372, 1.9135], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5425, 1.9372, 1.9135])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x = torch.randn(3,requires_grad = True)\n",
    "print(x)\n",
    "x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70765b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6317, 0.4076, 0.7472], requires_grad=True)\n",
      "tensor([2.6317, 2.4076, 2.7472])\n"
     ]
    }
   ],
   "source": [
    " x = torch.randn(3,requires_grad = True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y = x+2 #some operation is required\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4ad011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4.])\n",
      "tensor([8., 8., 8., 8.])\n",
      "tensor([12., 12., 12., 12.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4,requires_grad= True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*4).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    #print(model_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fb8a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4.])\n",
      "tensor([4., 4., 4., 4.])\n",
      "tensor([4., 4., 4., 4.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4,requires_grad= True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*4).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()\n",
    "    \n",
    "    #print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1a214",
   "metadata": {},
   "source": [
    "### Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956c5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generally their are three steps:\n",
    "#1.forward Pass: compute tge lossses\n",
    "#2.computation of local gradinents\n",
    "#3.backward pass : compute (dLoss/dweights) using chain rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b511d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0,requires_grad = True)\n",
    "\n",
    "#following the above steps\n",
    "y_hat = w*x\n",
    "loss = (y_hat-y)**2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a802c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a6ea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e514a",
   "metadata": {},
   "source": [
    "## Gradient Decent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad4ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    " import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7165e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32) \n",
    "\n",
    "\n",
    "\n",
    "#w = torch.tensor(0.0,dtype = torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f0924ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[0][0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "399999ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_fetures = X.shape\n",
    "print(n_fetures,n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09cdfb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor([5],dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98ea955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_fetures\n",
    "output_size = n_fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "031f0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def forward(x):\n",
    " #   return w*x\n",
    "#model = nn.Linear(input_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8417afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        self.lin = nn.Linear(input_dim,output_dim)\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "model = LinearRegression(input_size,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e920d",
   "metadata": {},
   "source": [
    "def loss(y,y_predict):\n",
    "    return ((y_predict-y)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc631cbf",
   "metadata": {},
   "source": [
    "def gradient(x,y,y_predict):\n",
    "    return np.dot(2*x,y_predict-y).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8ec71812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6202086210250854\n"
     ]
    }
   ],
   "source": [
    "print(model(X_test).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "625041ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "no_itr = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4db50b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd6c7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67829636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.139,loss=32.78094864\n",
      "epoch 101: w = 1.776,loss=0.07258532\n",
      "epoch 201: w = 1.834,loss=0.03984851\n",
      "epoch 301: w = 1.877,loss=0.02187636\n",
      "epoch 401: w = 1.909,loss=0.01200985\n",
      "epoch 501: w = 1.933,loss=0.00659328\n",
      "epoch 601: w = 1.950,loss=0.00361963\n",
      "epoch 701: w = 1.963,loss=0.00198714\n",
      "epoch 801: w = 1.973,loss=0.00109091\n",
      "epoch 901: w = 1.980,loss=0.00059890\n",
      "epoch 1001: w = 1.985,loss=0.00032879\n",
      "epoch 1101: w = 1.989,loss=0.00018050\n",
      "epoch 1201: w = 1.992,loss=0.00009909\n",
      "epoch 1301: w = 1.994,loss=0.00005440\n",
      "epoch 1401: w = 1.995,loss=0.00002987\n",
      "epoch 1501: w = 1.997,loss=0.00001640\n",
      "epoch 1601: w = 1.998,loss=0.00000900\n",
      "epoch 1701: w = 1.998,loss=0.00000494\n",
      "epoch 1801: w = 1.999,loss=0.00000271\n",
      "epoch 1901: w = 1.999,loss=0.00000149\n",
      "9.998448371887207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(no_itr):\n",
    "    #prediction = forward pass\n",
    "    y_pred  = model(X)\n",
    "    \n",
    "    #loss\n",
    "    l = loss(Y,y_pred)\n",
    "    #gradient\n",
    "    l.backward()\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    \n",
    "    if epoch % 100 ==0:\n",
    "        [w,b] = model.parameters() \n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f},loss={l:.8f}')\n",
    "print(model(X_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937e3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f909cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a442487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a3a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b5069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "293bb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value, y_value = datasets.make_regression(n_samples = 100,n_features = 1,noise = 20,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fa2dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasforms to tensor\n",
    "X = torch.from_numpy(x_value.astype(np.float32))\n",
    "Y = torch.from_numpy(y_value.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7af0cbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6118],\n",
       "        [-0.2494],\n",
       "        [ 0.4885],\n",
       "        [ 0.7620],\n",
       "        [ 1.5198],\n",
       "        [ 0.3776],\n",
       "        [ 0.5129],\n",
       "        [-0.6712],\n",
       "        [-1.3965],\n",
       "        [ 0.3156],\n",
       "        [-0.6370],\n",
       "        [-0.3968],\n",
       "        [-1.1006],\n",
       "        [ 0.9009],\n",
       "        [-1.0999],\n",
       "        [ 0.8280],\n",
       "        [-0.0756],\n",
       "        [-0.3522],\n",
       "        [-0.6707],\n",
       "        [-1.0730],\n",
       "        [-0.3062],\n",
       "        [ 2.1856],\n",
       "        [ 0.8654],\n",
       "        [ 0.1983],\n",
       "        [-0.3841],\n",
       "        [-0.6837],\n",
       "        [ 0.0508],\n",
       "        [ 0.5828],\n",
       "        [ 1.2529],\n",
       "        [-0.7544],\n",
       "        [-0.3493],\n",
       "        [-0.8876],\n",
       "        [ 0.1866],\n",
       "        [ 0.8762],\n",
       "        [ 0.8390],\n",
       "        [-0.5045],\n",
       "        [-0.3439],\n",
       "        [ 1.6925],\n",
       "        [-2.3015],\n",
       "        [ 0.9311],\n",
       "        [ 2.1003],\n",
       "        [ 1.4621],\n",
       "        [-0.8452],\n",
       "        [-0.8779],\n",
       "        [-0.3224],\n",
       "        [ 0.8851],\n",
       "        [ 0.1600],\n",
       "        [ 1.1316],\n",
       "        [-0.3753],\n",
       "        [ 0.5025],\n",
       "        [-0.2089],\n",
       "        [ 0.1202],\n",
       "        [ 0.5866],\n",
       "        [ 0.3190],\n",
       "        [-0.6917],\n",
       "        [ 0.6980],\n",
       "        [ 1.1989],\n",
       "        [-0.2008],\n",
       "        [ 0.5304],\n",
       "        [ 0.7420],\n",
       "        [ 0.4101],\n",
       "        [ 0.1190],\n",
       "        [-0.7612],\n",
       "        [ 0.4235],\n",
       "        [ 0.3002],\n",
       "        [-1.1425],\n",
       "        [ 0.1852],\n",
       "        [-0.9358],\n",
       "        [-0.6200],\n",
       "        [-1.1173],\n",
       "        [-1.4441],\n",
       "        [-0.2223],\n",
       "        [ 1.6243],\n",
       "        [ 0.6172],\n",
       "        [-0.6872],\n",
       "        [ 0.0773],\n",
       "        [-0.0127],\n",
       "        [-0.6387],\n",
       "        [ 1.1338],\n",
       "        [ 1.7448],\n",
       "        [ 0.9016],\n",
       "        [-2.0601],\n",
       "        [ 0.2344],\n",
       "        [-0.1724],\n",
       "        [ 0.1218],\n",
       "        [ 1.1447],\n",
       "        [-0.1229],\n",
       "        [-0.7472],\n",
       "        [ 0.2856],\n",
       "        [-2.0222],\n",
       "        [ 0.2301],\n",
       "        [-0.2679],\n",
       "        [-0.5282],\n",
       "        [ 1.1295],\n",
       "        [ 0.1909],\n",
       "        [-0.2981],\n",
       "        [ 1.6598],\n",
       "        [ 0.0436],\n",
       "        [ 0.0422],\n",
       "        [-0.1918]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2626b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9e98abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.view(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bef6683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0191208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e8822b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "\n",
    "input_size = n_features\n",
    "out_size = 1\n",
    "model = nn.Linear(input_size,out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c55100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a loss and optimizer function\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9f1dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1,loss = 332.5676\n",
      "epoch : 2,loss = 332.5676\n",
      "epoch : 3,loss = 332.5676\n",
      "epoch : 8,loss = 332.5676\n",
      "epoch : 9,loss = 332.5676\n",
      "epoch : 10,loss = 332.5676\n",
      "epoch : 11,loss = 332.5676\n",
      "epoch : 16,loss = 332.5676\n",
      "epoch : 17,loss = 332.5676\n",
      "epoch : 18,loss = 332.5676\n",
      "epoch : 19,loss = 332.5676\n",
      "epoch : 24,loss = 332.5676\n",
      "epoch : 25,loss = 332.5676\n",
      "epoch : 26,loss = 332.5676\n",
      "epoch : 27,loss = 332.5676\n",
      "epoch : 128,loss = 332.5676\n",
      "epoch : 129,loss = 332.5676\n",
      "epoch : 130,loss = 332.5676\n",
      "epoch : 131,loss = 332.5676\n",
      "epoch : 136,loss = 332.5676\n",
      "epoch : 137,loss = 332.5676\n",
      "epoch : 138,loss = 332.5676\n",
      "epoch : 139,loss = 332.5676\n",
      "epoch : 144,loss = 332.5676\n",
      "epoch : 145,loss = 332.5676\n",
      "epoch : 146,loss = 332.5676\n",
      "epoch : 147,loss = 332.5676\n",
      "epoch : 152,loss = 332.5676\n",
      "epoch : 153,loss = 332.5676\n",
      "epoch : 154,loss = 332.5676\n",
      "epoch : 155,loss = 332.5676\n",
      "epoch : 256,loss = 332.5676\n",
      "epoch : 257,loss = 332.5676\n",
      "epoch : 258,loss = 332.5676\n",
      "epoch : 259,loss = 332.5676\n",
      "epoch : 264,loss = 332.5676\n",
      "epoch : 265,loss = 332.5676\n",
      "epoch : 266,loss = 332.5676\n",
      "epoch : 267,loss = 332.5676\n",
      "epoch : 272,loss = 332.5676\n",
      "epoch : 273,loss = 332.5676\n",
      "epoch : 274,loss = 332.5676\n",
      "epoch : 275,loss = 332.5676\n",
      "epoch : 280,loss = 332.5676\n",
      "epoch : 281,loss = 332.5676\n",
      "epoch : 282,loss = 332.5676\n",
      "epoch : 283,loss = 332.5676\n",
      "epoch : 384,loss = 332.5676\n",
      "epoch : 385,loss = 332.5676\n",
      "epoch : 386,loss = 332.5676\n",
      "epoch : 387,loss = 332.5676\n",
      "epoch : 392,loss = 332.5676\n",
      "epoch : 393,loss = 332.5676\n",
      "epoch : 394,loss = 332.5676\n",
      "epoch : 395,loss = 332.5676\n",
      "epoch : 400,loss = 332.5676\n",
      "epoch : 401,loss = 332.5676\n",
      "epoch : 402,loss = 332.5676\n",
      "epoch : 403,loss = 332.5676\n",
      "epoch : 408,loss = 332.5676\n",
      "epoch : 409,loss = 332.5676\n",
      "epoch : 410,loss = 332.5676\n",
      "epoch : 411,loss = 332.5676\n",
      "epoch : 512,loss = 332.5676\n",
      "epoch : 513,loss = 332.5676\n",
      "epoch : 514,loss = 332.5676\n",
      "epoch : 515,loss = 332.5676\n",
      "epoch : 520,loss = 332.5676\n",
      "epoch : 521,loss = 332.5676\n",
      "epoch : 522,loss = 332.5676\n",
      "epoch : 523,loss = 332.5676\n",
      "epoch : 528,loss = 332.5676\n",
      "epoch : 529,loss = 332.5676\n",
      "epoch : 530,loss = 332.5676\n",
      "epoch : 531,loss = 332.5676\n",
      "epoch : 536,loss = 332.5676\n",
      "epoch : 537,loss = 332.5676\n",
      "epoch : 538,loss = 332.5676\n",
      "epoch : 539,loss = 332.5676\n",
      "epoch : 640,loss = 332.5676\n",
      "epoch : 641,loss = 332.5676\n",
      "epoch : 642,loss = 332.5676\n",
      "epoch : 643,loss = 332.5676\n",
      "epoch : 648,loss = 332.5676\n",
      "epoch : 649,loss = 332.5676\n",
      "epoch : 650,loss = 332.5676\n",
      "epoch : 651,loss = 332.5676\n",
      "epoch : 656,loss = 332.5676\n",
      "epoch : 657,loss = 332.5676\n",
      "epoch : 658,loss = 332.5676\n",
      "epoch : 659,loss = 332.5676\n",
      "epoch : 664,loss = 332.5676\n",
      "epoch : 665,loss = 332.5676\n",
      "epoch : 666,loss = 332.5676\n",
      "epoch : 667,loss = 332.5676\n",
      "epoch : 768,loss = 332.5676\n",
      "epoch : 769,loss = 332.5676\n",
      "epoch : 770,loss = 332.5676\n",
      "epoch : 771,loss = 332.5676\n",
      "epoch : 776,loss = 332.5676\n",
      "epoch : 777,loss = 332.5676\n",
      "epoch : 778,loss = 332.5676\n",
      "epoch : 779,loss = 332.5676\n",
      "epoch : 784,loss = 332.5676\n",
      "epoch : 785,loss = 332.5676\n",
      "epoch : 786,loss = 332.5676\n",
      "epoch : 787,loss = 332.5676\n",
      "epoch : 792,loss = 332.5676\n",
      "epoch : 793,loss = 332.5676\n",
      "epoch : 794,loss = 332.5676\n",
      "epoch : 795,loss = 332.5676\n",
      "epoch : 896,loss = 332.5676\n",
      "epoch : 897,loss = 332.5676\n",
      "epoch : 898,loss = 332.5676\n",
      "epoch : 899,loss = 332.5676\n",
      "epoch : 904,loss = 332.5676\n",
      "epoch : 905,loss = 332.5676\n",
      "epoch : 906,loss = 332.5676\n",
      "epoch : 907,loss = 332.5676\n",
      "epoch : 912,loss = 332.5676\n",
      "epoch : 913,loss = 332.5676\n",
      "epoch : 914,loss = 332.5676\n",
      "epoch : 915,loss = 332.5676\n",
      "epoch : 920,loss = 332.5676\n",
      "epoch : 921,loss = 332.5676\n",
      "epoch : 922,loss = 332.5676\n",
      "epoch : 923,loss = 332.5676\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "#training pipe line\n",
    "l= torch.tensor(1.0)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass\n",
    "    y_predict = model(X)\n",
    "    loss = criterion(y_predict,Y)\n",
    "    #backwardpass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update zhe wirghts\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) & 100 == 0:\n",
    "        print(f'epoch : {epoch+1},loss = {loss.item():.4f}')\n",
    "\n",
    "print(model(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d2926d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(x_value,y_value,'ro')\n",
    "plt.plot(x_value,predicted,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb821a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
